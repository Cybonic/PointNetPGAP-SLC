

experim_name: 'default'
################################################################################
# training parameters
################################################################################
pretrained_root: 'checkpoints'
n_gpu: 1

retrieval:
  top_cand: [1,5,25]
  range_thres: 6

max_points: 5000
aug: True 

base_dir: "uk"
memory: "DISK"
modality: "bev"

# Ground-truth parameters
ground_truth:
  e3:
    pos_range: 2.5 # Loop Threshold [m]
    neg_range: 10
    num_neg: 10
    num_pos: 1
    warmupitrs: 250 # Number of frames to ignore at the beguinning
    roi: 100

# Dataset parameters
train_loader:
  sequence: ['e3/extracted'] #['02','05','06','08']
  fraction: 0.3 
  batch_size: 1       # batch size
  shuffle: True
  #rotation: [180,-45,-45]
  
val_loader:
  dataset: ''
  sequence: ['e3/extracted']
  batch_size: 1 #50         # batch size
  workers:  0            # number of threads to get data
  shuffle: False


modelwrapper:
  type: 'ORCHNet'
  minibatch_size: 10


loss:
  type: 'TripletLoss'
  args:
    margin: 0.5
    metric: 'L2' # [L2,Hinge,cosine,kl_divergence]
    reduction: 'mean'

trainer:
  iter_per_epoch: 1
  epochs: 50
  report_val: 1      # every x epochs, report validation set
  save_period: 1
  log_dir: "saved/"
  save_dir: "checkpoints/"
  monitor: "max recall" # [off, max mIoU]
  val_per_epochs: 1
  eval_metric: 'L2'
  results_dir: "/media/tiago/BIG/Orchards/temp/"


optimizer:
  type: "AdamW" #[RMSprop,Adam,SGD]
  args:
    lr: 0.01
    weight_decay: 0.00000005
  lr_scheduler: "ReduceLROnPlateau"

StepLR:
  step_size: 20 
  gamma: 0.1

CosineAnnealingWarmRestarts:
  T_0: 5
  T_mult: 2
  eta_min: 0.00001 # Min learning rate

ReduceLROnPlateau:
  mode: 'min' #['min','max'] (str)
  factor: 0.01
  patience: 10 # Number of epochs with no improvement after which learning rate will be reduced. 
  min_lr: 0.000001

